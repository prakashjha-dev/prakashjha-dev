# ğŸ‘‹ Hi, I'm Prakash Jha

- ğŸ“ B.Tech Graduate (2024) | Currently working as a .NET Developer (1+ year industry experience)  
- ğŸ”§ Building expertise in **Data Engineering, ETL Pipelines, SQL, and Cloud Platforms**  
- ğŸ“Š Skilled in **Python, SQL, Data Modeling, APIs, and Workflow Automation**  
- ğŸŒ Exploring **Big Data, Streaming Pipelines, and Cloud Data Solutions**  
- ğŸ“‚ Maintaining hands-on projects in Data Engineering

---

## ğŸ› ï¸ Technical Skillset

- **Languages**: Python, SQL, C#, C++  
- **Databases**: SQL Server, PostgreSQL, MySQL  
- **Data Tools**: Pandas, NumPy, Jupyter, Airflow, Kafka  
- **Version Control**: Git, GitHub  
- **Other**: APIs, ETL workflows, basic DevOps practices  

---

## ğŸ“Œ Featured Projects (Portfolio)

| Project | Description | Tech Stack |
|---|-------------|-------------|
| [CSV to Database ETL Pipeline](#) | End-to-end ETL pipeline for raw CSV â†’ clean/transform â†’ load into SQL database | Python, Pandas, SQLAlchemy |
| [API Data Ingestion Pipeline](#) | Automated pipeline to pull data from a REST API, process, and load into database | Python, Requests, Airflow, PostgreSQL |
| [Batch Pipeline with Scheduling](#) | Batch workflow to ingest files daily, transform, and load into a warehouse | Python, Pandas, Airflow |
| [Data Lakehouse Mini Project](#) | Lakehouse-style project with raw + processed data layers | AWS S3, AWS Glue, Redshift |
| [Streaming Data Pipeline](#) | Real-time ingestion pipeline to process and store streaming data | Python, Apache Kafka, Spark |
| [Data Quality & Monitoring](#) | Automated checks for schema, nulls, anomalies in incoming datasets | Python, Great Expectations, SQL |

---

## ğŸ“« Connect

- LinkedIn: 
- GitHub: prakashjha-dev(https://github.com/prakashjha-dev)  
- Email: prakashjha050201@gmail.com
